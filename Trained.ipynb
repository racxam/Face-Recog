{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90068075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.models import Sequential\n",
    "from keras. layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4e8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR='images/train'\n",
    "TEST_DIR='images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8ac67d4-206e-4cf3-a789-0c60c4cf5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataFrame(dir):\n",
    "    img_paths=[]\n",
    "    labels=[]\n",
    "    for label in os.listdir(dir):\n",
    "        for imagename in os.listdir(os.path.join(dir,label)):\n",
    "            img_paths.append(os.path.join(dir,label,imagename))\n",
    "            labels.append(label)\n",
    "        print(label,\"done\")\n",
    "    return img_paths,labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680193e6-b16d-47cb-b965-041053fced72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy done\n",
      "sad done\n",
      "fear done\n",
      "surprise done\n",
      "neutral done\n",
      "angry done\n",
      "disgust done\n"
     ]
    }
   ],
   "source": [
    "train= pd.DataFrame()\n",
    "train['image'],train['label']= create_DataFrame(TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af37916-815b-4997-8538-5df5018bc198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                image    label\n",
      "0         images/train/happy/3578.jpg    happy\n",
      "1        images/train/happy/16988.jpg    happy\n",
      "2         images/train/happy/2666.jpg    happy\n",
      "3         images/train/happy/5109.jpg    happy\n",
      "4        images/train/happy/11981.jpg    happy\n",
      "...                               ...      ...\n",
      "28816  images/train/disgust/10112.jpg  disgust\n",
      "28817  images/train/disgust/21668.jpg  disgust\n",
      "28818   images/train/disgust/7049.jpg  disgust\n",
      "28819   images/train/disgust/9716.jpg  disgust\n",
      "28820   images/train/disgust/3561.jpg  disgust\n",
      "\n",
      "[28821 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "535d0ff7-6bb6-466b-ae60-96896073a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy done\n",
      "sad done\n",
      "fear done\n",
      "surprise done\n",
      "neutral done\n",
      "angry done\n",
      "disgust done\n"
     ]
    }
   ],
   "source": [
    "test=pd.DataFrame()\n",
    "test['image'],test['label']= create_DataFrame(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3133147a-5353-4d66-8040-fe1d2aef51b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              image    label\n",
      "0       images/test/happy/23933.jpg    happy\n",
      "1       images/test/happy/24906.jpg    happy\n",
      "2       images/test/happy/18033.jpg    happy\n",
      "3       images/test/happy/15271.jpg    happy\n",
      "4       images/test/happy/26888.jpg    happy\n",
      "...                             ...      ...\n",
      "7061  images/test/disgust/20761.jpg  disgust\n",
      "7062  images/test/disgust/28710.jpg  disgust\n",
      "7063  images/test/disgust/23876.jpg  disgust\n",
      "7064   images/test/disgust/9460.jpg  disgust\n",
      "7065  images/test/disgust/35580.jpg  disgust\n",
      "\n",
      "[7066 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372d3824-db24-470d-9f39-52a57dade9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_Features(images):\n",
    "    features=[]\n",
    "    for image in tqdm(images):\n",
    "        img=load_img(image,grayscale=True)\n",
    "        img= np.array(img)\n",
    "        features.append(img)\n",
    "    features= np.array(features)\n",
    "    features=features.reshape(len(features),48,48,1)\n",
    "    return features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35925ebf-47d1-4b2c-a6f5-04c47fe07b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf03d87811f44cc8872e01a203aa81a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28821 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sumitkumar/Documents/Face Recog/venv/lib/python3.10/site-packages/keras/src/utils/image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_features= extract_Features(train['image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f640b19-ba5e-423f-b674-ab14bc67fc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9dc676441b41f29fa0c05131d63e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7066 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_features=extract_Features(test['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176c69e4-077d-4dbb-b41b-42deca90258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= train_features/255.0\n",
    "\n",
    "x_test= test_features/255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e448b4-9fbd-4e7d-bc6a-3e42c15f6d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le= LabelEncoder()\n",
    "le.fit(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45868609-0ccf-4883-b392-2e31092a162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=le.transform(train['label'])\n",
    "y_test= le.transform(test['label'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df30ddfa-1135-4898-ae21-f2714126e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train,num_classes=7)\n",
    "y_test=to_categorical(y_test,num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218de69b-964d-4c56-88ff-bbc6329305bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "#CNN layer\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "# fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "# output layer\n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76c399bc-3523-4c05-be89-ebb421e9009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(10^4), loss = 'categorical_crossentropy', metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a77c596-bb4f-41f2-b107-9709f779c06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "198/226 [=========================>....] - ETA: 43s - loss: nan - accuracy: 0.1399"
     ]
    }
   ],
   "source": [
    "model.fit(x= x_train,y = y_train, batch_size = 128, epochs = 28, validation_data = (x_test,y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b3459-cc36-424c-b01a-5e7c53f7d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_json= model.to_json()\n",
    "# with open(\"Emotion_recog_for_gaming.json\",'w') as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# model.save(\"Emotion_recog_for_gaming.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126009a-f7d7-4f37-a1a2-ec65cd968fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
